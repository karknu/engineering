---
slug: 2023-05-30-p2p
title: "Unveiling Cardano's Dynamic P2P Release: A Leap Forward in Decentralization"
authors: [bolt12]
tags: [networking, p2p]
custom_edit_url: null
---

## Introduction

As the Cardano ecosystem continues to grow and evolve, we at [IOG] with our partners at
[Well-Typed], [PNSol] and [CF] are committed to constantly refining and optimising our
networking infrastructure. Cardano's new highly performant, dynamic Peer-to-Peer (P2P)
release marks a major milestone in its journey towards creating a fully decentralized and
secure blockchain platform. Dynamic peer-to-peer (P2P) networking was released with node
v.1.35.6 release.

As a real-time stochastic system, Cardano's performance and security are inherently
intertwined. Our team, remains committed to identifying the perfect equilibrium between
various factors, such as topological and topographic considerations that can improve
timeliness, and connectivity.

In this blog post, we'll explore the engineering journey behind the
development of Cardano's Dynamic P2P design. We'll cover the core design principles, the
challenges we faced along the way, and the solutions we devised to create a robust and
scalable networking system.

### What's Dynamic P2P

The Dynamic P2P implementation continuously and dynamically refines the active topology
through a peer selection process that aims to *reduce overall diffusion time across the
entire network*. Our research findings indicate that using a policy based solely on local
information can lead to a nearly optimal global outcome. This is accomplished by tracking
the timeliness and frequency of peers providing a block header that ultimately gets
incorporated into the chain.

The primary goal is to eliminate highly "non-optimal" peers while maintaining strong
connectivity. To achieve this, peers considered less useful based on this metric are
periodically "churned out" and replaced with randomly selected alternatives. Simulation
results show that this optimization method approaches a near-optimal global
result within a relatively small number of iterations.

Practically, Dynamic P2P replaces the manual configuration of peer selection (e.g. using
the topology updater tool).

With manual configuration, SPOs were required to establish connections with numerous
peers, for instance, 50, to ensure a consistent minimum of 20 active connections. This was
necessary due to the static nature of configured peers and the fluctuating availability of
SPO relays.

However, with dynamic P2P, nodes can be set to target a specific number of active peer
nodes (e.g. 20) and choose from all registered SPO relays on the chain. If a connection
with a peer is lost, the node will automatically select alternative peers and continue
attempting connections to peers until the desired target is achieved.

As a result, dynamic P2P eliminates the need for over-provisioning connections, providing
a more efficient and adaptable networking solution.

## The Design Vision

Cardano is ultimately a cooperating system of autonomous nodes. It is not a client-server
design, so there is fundamentally no central point of control nor any privileged class of
centrally managed servers. Although, with respect to its network topology, it might have
started as a federated network (in Byron era), our goal was to converge into a fully,
trustless distributed networking system that could handle the evolving demands of the
Cardano ecosystem while ensuring good connectivity and performance.

As the networking team embarked on this engineering adventure, we knew we would encounter
numerous challenges and complexities. We embraced those and kept heading towards them,
constantly refining the set of pivotal ideas that would eventually shape our Dynamic P2P
design:

1. **Modularity and Extensibility**: We designed the system with modularity in mind, making it
   easy to swap out or improve individual components as needed. This extensibility allows
   for seamless integration of new features and enhancements, ensuring that our design
   remains adaptive to the evolving needs of the Cardano ecosystem. Modularity is
   especially helpful if and when we apply formal methods to prove correctness of low
   level designs with respect to high level specifications. By breaking down the system
   into smaller, more manageable components, we can apply property-based testing more
   effectively to each module, ensuring that the behavior of each part is well-defined and
   adheres to the expected properties. Of course, picking Functional Programming with
   Haskell as our primary programming language played a significant role in achieving this
   level of modularity and extensibility.

2. **Scalability**: As the network grows, so does the need for a system that can handle a
   larger number of nodes and transactions, while ensuring it still respects Ouroboros
   timing constraints. For our P2P design vision, we took scalability into account from
   the outset, incorporating strategies such as intelligent peer selection.

3. **Security and Resilience**: In a decentralized network, resilience and security are of
   paramount importance. We focused on building a system that could withstand both
   internal and external disruptions, by employing techniques such as robust error
   handling mechanisms, designed for (but not only) resilience to abuse, meaning that
   users should not be able to attack the system using an asymmetric denial of service
   attack that will deplete network resources from other users.

   With P2P, each node is able to prioritise its connection to locally configured peers,
   which ensures it is always maintains connection to trusted peers and is able to make
   progress in the network. Rate limiting inbound connections and configurable peer
   targets allow the node to adjust its resource consumption. Careful management of
   connection states, allow the re-use of duplex connections, enables nodes behind
   firewalls to improve their connectivity safely while reducing the overall attack
   surface.

4. **Performance**: A high-performance network is essential for a seamless user experience. We
   dedicated significant effort to optimizing our design, utilizing techniques such as:
   efficient data transmission via multiplexing; and protocols that support pipelining.
   Intelligent peer selection will contribute latency reduction to guarantee a
   responsive and reliable network.

Achieving low latency and good connectivity is essential to establishing effective
communication within the Cardano network. Our Dynamic P2P design has been crafted to
ensure that these prerequisites are met, providing a robust, scalable, and resilient
foundation for the continued growth of the ecosystem. However, it is important to
acknowledge that the trustworthiness of the peers you connect to is also a critical factor
in maintaining a secure and reliable network. While addressing trustworthiness in depth
would steer us beyond the scope of this blog post, it is worth noting that our design
incorporates multiple measures to mitigate potential risks and safeguard the network.

## Dynamic P2P

Ensuring the performance and security of Ouroboros is crucial, and one critical aspect of
this is the timely relay of new blocks across the network. Ideally, the connections within
the P2P network should be arranged to minimize the time required for a block to be relayed
from any node to all other nodes in the network.

However, this turns out to be a complex challenge, with limited prior work available that
is applicable in a trustless setting. Addressing this problem effectively required
innovative solutions that can balance the need for swift communication while maintaining
the integrity and security of the decentralized network.

### Why it's a hard problem

An effective solution to optimize performance would minimize the number of "hops" a block
has to take across the network. In terms of a graph, this equates to reducing the average
number of edges a block traverses. Additionally, the length of each hop or edge is
significant. Local links exhibit lower latency compared to intercontinental links;
however, some intercontinental links are necessary for worldwide block relay. For
instance, a suboptimal solution would involve traversing excessive intercontinental links,
such as from Europe to Asia and back again.

Existing networking algorithms can generate optimal "spanning trees," which could serve as
paths for block relay. However, these algorithms depend on nodes trusting each other to
exchange accurate information, which is unsuitable for a blockchain P2P network where
nodes cannot inherently trust each other.

An ideal solution must rely on "local" rather than "global" information â€” information that
nodes can individually assess without depending on shared, trustworthy data. Nonetheless,
having an optimal solution that relies on perfect global information serves as a valuable
reference point.

#### Preliminary research

In collaboration with network researchers from Athens University, specialists in
decentralized systems and their protocols, we embarked on a crucial task: simulating
various network policies and studying the trade-offs in diffusion time.

The pivotal question surrounding dissemination is the establishment of who forwards blocks
to whom, or more precisely, which dissemination links should be formed among nodes to
enhance dissemination speed.

In addressing this question, the researchers pursued two primary approaches:

- The first strategy assumes links are independent of the dissemination process. By
  simulating a static overlay where links are established based on predefined rules, and
  then multiple disseminations are run, in order to measure performance.

- The second strategy involves dynamically adjusting the overlay. Here, nodes initially
  establish connections with random nodes in the network and keep track of performance
  statistics for evaluating their neighbors. Periodically, each node adjusts its set of
  neighbors based on these statistics, deciding which neighbors to keep and which ones to
  replace.

![Close random policy](/img/close-random-graph-1.png)

The plot shows how quickly a block disseminates through the network eventually arriving to
all nodes.

It also confirms the effectiveness of our approach to the challenge of efficient
diffusion. In this experiment all nodes use exactly the same Close-Random policy as
detailed for the previous graph. All nodes start as uninformed nodes, i.e. they have not
received a given block yet, and they become informed at some point over the course of the
experiment. The dotted line represents the theoretical optimal solution, which is
contingent on all informed nodes having complete knowledge about which peers are the most
beneficial for them, making such connections.

It's important to clarify that we do not actually implement the Close-Random policy.
Instead, we use it as a practical theoretical tool. It offers a balance, being not purely
local, yet simple enough to be approximated with only local information.

This analysis shows us how close to a perfect solution we can get using almost local
information. The interesting part is how this approach outperforms expectations -
achieving a result within a factor of two of perfection would have been commendable, but
we discovered that we can do even better.

![Close random policy](/img/calibrations.png)

The figure above compares the outcomes from the two approaches described earlier. The
simulation involved each node maintaining 6 "close" neighbors (based on
Round Trip Time (RTT)), and 4 random nodes. These links were kept static throughout the
entire experiment (hence the constant blue lines). In the "2 groups (<=100ms and >100ms)"
policy, each node maintains a fixed number of close links and remote links: "close"
signifies that the RTT to that neighbor is less or equal to 100 ms, while "remote" implies
that the RTT is more than 100 ms. Nodes start with all random links and periodically
calibrate. During this calibration, they retain up to a fixed number of neighbors that
have an RTT of less than 100 ms, and they replace some of the remaining neighbors with
newly picked random nodes.

The graph lets us infer how many churn cycles one needs to get optimal global
dissemination and illustrates that when using local information to calibrate its
connections to other peers, one can gradually approach an optimal result. As shown,
periodic recalibrations lead to a progressive improvement in the overall dissemination
performance.

![Average dissemination](/img/stake_uniform.png)

This final graph presents the average dissemination time under different policy mixes,
specifically changes in a node's neighbor-selection strategy. As explained before, we have
the Close (C) and Random (R) policies. For the purposes of this plot a new
element is introduced, the Score (S) based policy, where a node uses a scoring function to
determine the usefulness of its current neighbors. This scoring function allocates a single
'bounty' point to the node that first delivers a new block. After every 100 blocks, the
'S' nodes exhibiting the highest performance across all neighbors (including C, R, and S
sets) are selected to replenish the 'S' set. This process likely results in the
replacement of some previous nodes within that set.

This heat map gives us a rich visual representation of how these varying policies interact
and influence overall network performance. It showcases the trade-offs in adopting
different proportions of 'C', 'R', and 'S' policies, highlighting the impact each has on
average dissemination time. This data is invaluable as it guides us in designing with and
fine-tuning our system to achieve optimal network performance.

Our comparative study between a trustless, locally-informed solution and the ideal
benchmark provided insightful data regarding our progress towards optimal performance.
It's important to clarify that these policies are not being applied in our production
environment (see the next section an explanation of the policies we use). Instead, they
were utilized within our research framework to ascertain the degree of guidance necessary
in our policies for achieving optimal outcomes. The findings from this investigation were
indeed intriguing.

### P2P networking based on local information

In our dynamic P2P design, each node maintains a local view of the network and evaluates
potential connections considering factors such as latency, throughput, and historical
performance. Nodes continuously monitor and adjust their connections, seeking
better-performing peers to optimize their network position and minimize the number of hops
required for block relay.

Each node maintains three sets of known peer nodes:

- *Cold* peers: are known peers without an established network connection;
- *Warm* peers: are peers with an established bearer connection, used solely for network
  measurements and not for any application-level consensus protocols;
- *Hot* peers: are peers with an active bearer connection, utilized for the
  application-level consensus protocols.

As mentioned earlier, nodes maintain limited information about these peers, based on
previous direct interactions. For cold nodes, this information may often be absent due to
the lack of prior direct interactions. This information resembles "reputation" in other
systems, but it is essential to emphasize that it is purely local and not shared with any
other node.

![Sets of known peers](/img/peer-discovery.jpg)

The illustration above demonstrates the promotion/demotion cycle, managed by the Peer
Selection Governor (PSG). This component aims to achieve specific targets, such as a
designated number of known and active peers.

Local static configuration can also be used to designate certain known nodes as hot or
warm peers. This approach allows for fixed relationships between nodes managed by a single
organization, such as a stake pool with multiple relays. It also facilitates private
peering arrangements between stake pool operators and other probable deployment scenarios.

In instances of adversarial behavior, a peer can be immediately demoted from the hot,
warm, and cold sets. We opt not to maintain negative peer information for extended periods
to limit resource consumption in a permission-less system which could make Sybil attacks
quite simple.

#### Churning and Local Policies

The Peer Churn Governor (PCG) is a component that plays a pivotal role in managing the
health and efficiency of a network by navigating issues related to network partition and
eclipse attacks, by adjusting the values of the targets for hot, warm and cold peers so as
to promote their churning.

In this process, the PCG modifies the frequency at which peers are promoted (upgraded from
cold to warm, or warm to hot) or demoted (downgraded from hot to warm, or warm to cold).
This decision is guided by scoring functions that evaluate peers based on their usefulness
and performance.

These scoring functions include:

- **Hot Demotion Policy**: This function determines which 'hot' (highly active and valuable) peers
  should be demoted. The score is computed based on a peer's contribution to the network:
  the number of *blocks* it's been the first to provide and/or number of *bytes* provided.
  In times of normal operation, a combination of these factors is used, whereas during
  bulk sync data synchronization, the number of bytes provided takes precedence.

- **Warm Demotion Policy and Cold Forget Policy**: These functions deal with 'warm' and 'cold' peers
  respectively, deciding which should be downgraded or removed (in case of cold peers) from
  the network. The decisions are influenced by a degree of randomness, and certain
  characteristics like previous failures or a tepidity flag, indicating less reliable or
  less active peers.

During the process of a node syncing with the network, the PCG ensures that no more than
two active connections are used, preventing resource over-utilization. Once the node is
fully synced, the PCG facilitates a periodic 'churn', wherein it refreshes approximately
20% of the peers every hour, promoting a robust and adaptable network.

While the Close-Random or Score-based policies explored in the research aren't replicated
verbatim in the production environment, they have greatly influenced the design of
the implemented policies. The PCG employs scoring functions to dynamically assess and
adjust the peer network, reflecting the insights derived from the research simulations.
Furthermore, the PCG performs periodic churns, an approach which aligns with the dynamic
network adjustments also observed in the research. The graph, illustrating the trade-offs
and optimal dissemination times under different policy mixes, guided the integration of a
degree of randomness in the PCG's policies such as the Warm Demotion and Cold Forget
Policies. Thus, the research findings have served as a vital roadmap in shaping the
networking policies within the Cardano production environment.

## Development Approach

Cardano's P2P implementation is founded on the use of Haskell, a functional programming
language renowned for its correctness, safety, and maintainability. Haskell's powerful
type system helps identify potential issues during development, leading to more robust and
reliable code. In addition, we developed and employ [io-sim], a time-based discrete event
simulation library that provides precise control over entropy and timing during
simulations. This tool also faithfully simulates Haskell's runtime system, including
`STM`, `MVar`s, and more. This level of control allows for reproducibility, regression
testing, and examination of worst-case scenarios. By combining Haskell and [io-sim], we can
rigorously test the exact same code in the P2P production system under a wide range of
conditions, ensuring it is well-prepared to handle real-world challenges.

In our pursuit of creating a reliable system, we conduct extensive property based testing.
These tests are designed to find complex bugs and corner cases that might go unnoticed in
standard testing approaches (e.g. unit testing). One distinctive aspect of our testing
process is that it includes running simulations that replicate years of system operation.
This comprehensive approach allows us to mimic years' worth of activity, uncovering rare
bugs that may only surface under specific or extended conditions. However, it's important
to note that the quality of these tests ultimately depends on the quality of the
generators used, as they play a crucial role in producing diverse and representative
inputs for thorough evaluation.

[io-sim]: https://github.com/input-output-hk/io-sim
[ouroboros-network]: https://github.com/input-output-hk/ouroboros-network
[IOG]: https://iog.io/
[Well-Typed]: https://www.well-typed.com/
[PNSol]: http://www.pnsol.com/
[CF]: https://cardanofoundation.org/
